import os
from moviepy.editor import *
from utils import text_to_speech, add_text_to_clip, download_video_from_pexels
from openai_utils import split_script
import uuid
import tempfile
import logging

logger = logging.getLogger(__name__)

def create_video(script, topic):
    logger.info("ğŸ“½ï¸ ì˜ìƒ ìƒì„± ì‹œì‘...")

    # ë°°ê²½ ì˜ìƒ ë‹¤ìš´ë¡œë“œ
    background_video = download_video_from_pexels(topic)
    if not background_video:
        logger.error("âŒ ë°°ê²½ ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
        return None

    # ëŒ€ë³¸ ë¶„í• 
    sentences = split_script(script)
    if not sentences:
        logger.warning("âš ï¸ ëŒ€ë³¸ì´ ë¹„ì–´ ìˆìŒ")
        return None

    # ì˜¤ë””ì˜¤ ìƒì„± ë° ì˜ìƒ ì¡°í•©
    clips = []
    for idx, sentence in enumerate(sentences):
        logger.info(f"ğŸ¤ ìŒì„± ìƒì„± ì¤‘: {sentence}")
        audio_path = text_to_speech(sentence)

        if not audio_path or not os.path.exists(audio_path):
            logger.warning("âš ï¸ ìŒì„± ìƒì„± ì‹¤íŒ¨, ìŠ¤í‚µ")
            continue

        video = VideoFileClip(background_video).subclip(0, AudioFileClip(audio_path).duration)
        video = video.set_audio(AudioFileClip(audio_path))
        video = add_text_to_clip(video.filename, sentence, "temp_text.mp4")  # ìˆ˜ì •ëœ ë¶€ë¶„
        clips.append(video)

    if not clips:
        logger.error("âŒ í´ë¦½ ì—†ìŒ. ì˜ìƒ ìƒì„± ì‹¤íŒ¨")
        return None

    final_clip = concatenate_videoclips(clips, method="compose")
    output_path = os.path.join("output", f"{uuid.uuid4()}.mp4")
    os.makedirs("output", exist_ok=True)
    final_clip.write_videofile(output_path, fps=24)

    logger.info(f"âœ… ì˜ìƒ ìƒì„± ì™„ë£Œ: {output_path}")
    return output_path
